#!/bin/bash

# Setup Whisper.cpp - 100% Local, Zero Nuvem
# Roda no Mac (M3 Max) ou Linux (tower)

set -e

echo "ğŸ¤ BEAGLE Whisper Setup"
echo "======================="
echo ""

# Detecta sistema
if [[ "$OSTYPE" == "darwin"* ]]; then
    echo "âœ… macOS detectado"
    WHISPER_DIR="$HOME/whisper.cpp"
elif [[ "$OSTYPE" == "linux-gnu"* ]]; then
    echo "âœ… Linux detectado"
    WHISPER_DIR="$HOME/whisper.cpp"
else
    echo "âŒ Sistema nÃ£o suportado: $OSTYPE"
    exit 1
fi

# 1. Clona whisper.cpp
if [ ! -d "$WHISPER_DIR" ]; then
    echo "ğŸ“¦ Clonando whisper.cpp..."
    git clone https://github.com/ggerganov/whisper.cpp.git "$WHISPER_DIR"
    cd "$WHISPER_DIR"
else
    echo "âœ… whisper.cpp jÃ¡ existe"
    cd "$WHISPER_DIR"
    git pull
fi

# 2. Compila
echo ""
echo "ğŸ”§ Compilando whisper.cpp..."
make

if [ ! -f "$WHISPER_DIR/main" ]; then
    echo "âŒ Falha ao compilar whisper.cpp"
    exit 1
fi

echo "âœ… whisper.cpp compilado"

# 3. Baixa modelo
echo ""
echo "ğŸ“¥ Baixando modelo large-v3 (qualidade alta, ~1.5GB)..."
if [ ! -f "$WHISPER_DIR/models/ggml-large-v3.bin" ]; then
    cd "$WHISPER_DIR"
    bash models/download-ggml-model.sh large-v3
else
    echo "âœ… Modelo jÃ¡ existe"
fi

# 4. Testa
echo ""
echo "ğŸ§ª Testando whisper.cpp..."
if [ -f "$WHISPER_DIR/samples/jfk.wav" ]; then
    "$WHISPER_DIR/main" -m "$WHISPER_DIR/models/ggml-large-v3.bin" -f "$WHISPER_DIR/samples/jfk.wav" -l en --no-print-progress > /dev/null 2>&1
    echo "âœ… Teste passou"
else
    echo "âš ï¸  Arquivo de teste nÃ£o encontrado (ok, continua)"
fi

echo ""
echo "=" ^ 60)
echo "âœ… Whisper.cpp instalado e pronto!"
echo "=" ^ 60)
echo ""
echo "ğŸ“ LocalizaÃ§Ã£o:"
echo "   ExecutÃ¡vel: $WHISPER_DIR/main"
echo "   Modelo: $WHISPER_DIR/models/ggml-large-v3.bin"
echo ""
echo "ğŸš€ Como usar:"
echo "   cargo run --example voice_assistant --package beagle-whisper"
echo ""

