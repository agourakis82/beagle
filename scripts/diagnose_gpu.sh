#!/bin/bash
# GPU Environment Diagnostic

set -e

GREEN='\033[0;32m'
YELLOW='\033[1;33m'
RED='\033[0;31m'
NC='\033[0m'

function section() {
  echo ""
  printf "${YELLOW}%s${NC}\n" "$1"
  echo "--------------------------------------"
}

echo "ğŸ” BEAGLE GPU Environment Diagnostic"
echo "======================================"

section "1ï¸âƒ£  NVIDIA Driver"
if command -v nvidia-smi >/dev/null 2>&1; then
  nvidia-smi --query-gpu=driver_version --format=csv,noheader
else
  echo "nvidia-smi not available"
fi

section "2ï¸âƒ£  CUDA Version"
if command -v nvcc >/dev/null 2>&1; then
  nvcc --version
else
  echo "nvcc not in PATH"
fi
if [ -f /usr/local/cuda/version.txt ]; then
  cat /usr/local/cuda/version.txt
else
  echo "CUDA version file not found"
fi

section "3ï¸âƒ£  GPU Info"
if command -v nvidia-smi >/dev/null 2>&1; then
  nvidia-smi --query-gpu=name,compute_cap,memory.total --format=csv
else
  echo "nvidia-smi not available"
fi

section "4ï¸âƒ£  GPU Compute Mode"
if command -v nvidia-smi >/dev/null 2>&1; then
  nvidia-smi --query-gpu=compute_mode --format=csv
else
  echo "nvidia-smi not available"
fi

section "5ï¸âƒ£  MPS Status"
if pgrep -x nvidia-cuda-mps >/dev/null 2>&1; then
  echo "âš ï¸  NVIDIA MPS is RUNNING (may cause vLLM deadlock)"
  ps aux | grep -i mps | grep -v grep
else
  echo "âœ… NVIDIA MPS is NOT RUNNING"
fi

section "6ï¸âƒ£  GPU Processes"
if command -v nvidia-smi >/dev/null 2>&1; then
  nvidia-smi pmon -c 1 || true
else
  echo "nvidia-smi not available"
fi

section "7ï¸âƒ£  Docker GPU Runtime"
if command -v docker >/dev/null 2>&1; then
  docker run --rm --gpus all nvidia/cuda:12.0.0-base-ubuntu22.04 nvidia-smi || echo "GPU runtime not working"
else
  echo "Docker not available"
fi

section "8ï¸âƒ£  System Info"
uname -a

section "9ï¸âƒ£  CUDA libs"
ls -l /usr/lib/x86_64-linux-gnu | grep -i cuda | head -n 20 || true

section "ğŸ”š Diagnostic complete"
