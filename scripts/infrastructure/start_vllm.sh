#!/bin/bash
#
# vLLM Server Startup Script
# ===========================
# Inicia servidor vLLM com Qwen 2.5 32B GPTQ
#
# USO:
#   ./start_vllm.sh [opÃ§Ãµes adicionais para vllm]
#
# VARIÃVEIS DE AMBIENTE:
#   VLLM_PORT    - Porta do servidor (padrÃ£o: 8001)
#   VLLM_HOST    - Host do servidor (padrÃ£o: 0.0.0.0)
#   MODEL_DIR    - DiretÃ³rio do modelo (padrÃ£o: ~/models/qwen-32b-gptq)

set -e

# Cores
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
RED='\033[0;31m'
NC='\033[0m'

# ConfiguraÃ§Ãµes padrÃ£o
VENV_DIR="${HOME}/vllm-env"
MODEL_DIR="${MODEL_DIR:-${HOME}/models/qwen-32b-gptq}"
PORT="${VLLM_PORT:-8001}"
HOST="${VLLM_HOST:-0.0.0.0}"

# Verificar virtual environment
if [ ! -d "$VENV_DIR" ]; then
    echo -e "${RED}ERROR: Virtual environment nÃ£o encontrado em $VENV_DIR${NC}"
    echo "Execute: ./setup_vllm_t560.sh primeiro"
    exit 1
fi

# Ativar virtual environment
source "$VENV_DIR/bin/activate"

# Verificar modelo
if [ ! -d "$MODEL_DIR" ]; then
    echo -e "${RED}ERROR: Modelo nÃ£o encontrado em $MODEL_DIR${NC}"
    echo "Execute: huggingface-cli download Qwen/Qwen2.5-32B-Instruct-GPTQ-Int4 --local-dir $MODEL_DIR"
    exit 1
fi

# Verificar GPU
if ! command -v nvidia-smi &> /dev/null; then
    echo -e "${RED}ERROR: nvidia-smi nÃ£o encontrado${NC}"
    exit 1
fi

# Mostrar informaÃ§Ãµes
echo -e "${GREEN}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
echo -e "${GREEN}vLLM Server Starting...${NC}"
echo -e "${GREEN}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
echo ""
echo "ğŸ“¦ Modelo: $MODEL_DIR"
echo "ğŸŒ Host: $HOST"
echo "ğŸ”Œ Port: $PORT"
echo ""

# Mostrar status GPU
echo "ğŸ® GPU Status:"
nvidia-smi --query-gpu=name,memory.used,memory.total,temperature.gpu --format=csv,noheader
echo ""

# Iniciar servidor
echo -e "${YELLOW}Iniciando vLLM server...${NC}"
echo ""

python -m vllm.entrypoints.openai.api_server \
  --model "$MODEL_DIR" \
  --dtype half \
  --max-model-len 8192 \
  --gpu-memory-utilization 0.90 \
  --host "$HOST" \
  --port "$PORT" \
  --trust-remote-code \
  "$@"


