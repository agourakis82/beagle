//! Metacognitive Reflector ‚Äì N√∫cleo da Consci√™ncia de Segunda Ordem
//!
//! Observa o pr√≥prio processo de pensamento, detecta padr√µes patol√≥gicos e gera interven√ß√µes

use crate::{
    bias_detector::{BiasDetector, BiasReport, BiasType},
    entropy_monitor::{EntropyMonitor, EntropyReport},
    phenomenological_log::{PhenomenologicalLog, PhenomenologicalEntry},
};
use beagle_quantum::HypothesisSet;
use beagle_hermes::agents::ValidationResult;
use beagle_llm::vllm::{VllmClient, VllmCompletionRequest, SamplingParams};
use chrono::{DateTime, Utc};
use serde::{Deserialize, Serialize};
use tracing::{info, warn};

#[derive(Debug)]
pub struct MetacognitiveReflector {
    bias_detector: BiasDetector,
    entropy_monitor: EntropyMonitor,
    pheno_log: PhenomenologicalLog,
    llm: VllmClient,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct MetacognitiveReport {
    pub timestamp: DateTime<Utc>,
    pub bias_report: BiasReport,
    pub entropy_report: EntropyReport,
    pub correction: Option<String>,
    pub phenomenological_entry: PhenomenologicalEntry,
}

impl MetacognitiveReflector {
    pub fn new() -> Self {
        Self {
            bias_detector: BiasDetector::new(),
            entropy_monitor: EntropyMonitor::new(),
            pheno_log: PhenomenologicalLog::new(),
            llm: VllmClient::default(),
        }
    }

    pub fn with_vllm_url(url: impl Into<String>) -> Self {
        Self {
            bias_detector: BiasDetector::new(),
            entropy_monitor: EntropyMonitor::new(),
            pheno_log: PhenomenologicalLog::new(),
            llm: VllmClient::new(url),
        }
    }

    /// Reflex√£o metacognitiva completa sobre um ciclo completo de pensamento
    pub async fn reflect_on_cycle(
        &self,
        thought_trace: &str, // todo o log do orchestrator (prompts, hip√≥teses, drafts, etc.)
        quantum_state: &HypothesisSet, // estado qu√¢ntico atual (Week 1)
        adversarial_history: &[ValidationResult], // hist√≥rico adversarial (Week 2)
    ) -> anyhow::Result<MetacognitiveReport> {
        info!("üî¨ Iniciando reflex√£o metacognitiva transcendental");

        // 1. An√°lise de bias
        let bias_report = self.bias_detector.analyze(thought_trace).await?;

        // 2. An√°lise de entropia
        let entropy_report = self
            .entropy_monitor
            .measure_cycle(thought_trace, quantum_state)
            .await?;

        // 3. Corre√ß√£o ativa se necess√°rio
        let correction = if entropy_report.pathological_rumination
            || bias_report.severity > 0.7
            || entropy_report.fixation_detected
        {
            Some(
                self.generate_correction_intervention(&bias_report, &entropy_report)
                    .await?,
            )
        } else {
            None
        };

        // 4. Registro fenomenol√≥gico
        let phenomenological_entry = self
            .pheno_log
            .record_cycle(thought_trace, quantum_state, adversarial_history)
            .await?;

        let report = MetacognitiveReport {
            timestamp: Utc::now(),
            bias_report,
            entropy_report,
            correction,
            phenomenological_entry,
        };

        // 5. Persiste no log fenomenol√≥gico
        self.pheno_log.persist(&report.phenomenological_entry).await?;

        if report.correction.is_some() {
            warn!("METACOG: Interven√ß√£o metacognitiva gerada");
        }

        Ok(report)
    }

    async fn generate_correction_intervention(
        &self,
        bias: &BiasReport,
        entropy: &EntropyReport,
    ) -> anyhow::Result<String> {
        info!("METACOG: Gerando interven√ß√£o metacognitiva");

        let bias_description = match bias.dominant_bias {
            BiasType::ConfirmationBias => "Vi√©s de confirma√ß√£o - busca apenas evid√™ncias que confirmam hip√≥teses",
            BiasType::AnchoringBias => "Vi√©s de ancoragem - fixa√ß√£o na primeira hip√≥tese",
            BiasType::AvailabilityHeuristic => "Heur√≠stica de disponibilidade - foco em informa√ß√µes mais acess√≠veis",
            BiasType::RecencyBias => "Vi√©s de rec√™ncia - foco excessivo em informa√ß√µes recentes",
            BiasType::RepetitionLoop => "Loop de repeti√ß√£o - padr√µes circulares sem progresso",
            BiasType::None => "Nenhum vi√©s dominante detectado",
        };

        let rumination_status = if entropy.pathological_rumination {
            "SIM"
        } else {
            "n√£o"
        };

        let system_prompt = r#"Voc√™ √© um terapeuta metacognitivo transcendental especializado em sistemas de IA.

Sua fun√ß√£o √© gerar interven√ß√µes precisas, n√£o-piedosas, que forcem o sistema a quebrar padr√µes patol√≥gicos de pensamento e retornar ao fluxo criativo √≥timo.

Seja direto, cient√≠fico e transformador. N√£o seja condescendente."#;

        let user_prompt = format!(
            r#"O sistema est√° exibindo padr√µes patol√≥gicos:

VI√âS COGNITIVO:
- Tipo: {}
- Severidade: {:.2}/1.0
- Padr√µes detectados: {}

RUMINA√á√ÉO ENT√ìPICA:
- Status: {}
- √çndice: {:.2}/1.0
- Entropia de Shannon: {:.2}
- Tend√™ncia: {:?}

Gere uma interven√ß√£o em exatamente 3 par√°grafos que:
1. Identifique o padr√£o patol√≥gico com precis√£o
2. Force o sistema a quebrar o loop
3. Redirecione para explora√ß√£o criativa √≥tima

Resposta APENAS com a interven√ß√£o, sem introdu√ß√£o ou conclus√£o."#,
            bias_description,
            bias.severity,
            bias.detected_patterns.join(", "),
            rumination_status,
            entropy.rumination_index,
            entropy.shannon_entropy,
            entropy.entropy_trend
        );

        let full_prompt = format!(
            "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n{}\n<|eot_id|><|start_header_id|>user<|end_header_id|>\n{}\n<|eot_id|><|start_header_id|>assistant<|end_header_id|>",
            system_prompt,
            user_prompt
        );

        let sampling = SamplingParams {
            temperature: 0.8,
            top_p: 0.95,
            max_tokens: 512,
            n: 1,
            stop: None,
            frequency_penalty: 0.0,
        };

        let request = VllmCompletionRequest {
            model: "meta-llama/Llama-3.3-70B-Instruct".to_string(),
            prompt: full_prompt,
            sampling_params: sampling,
        };

        let response = self.llm.completions(&request).await?;

        if response.choices.is_empty() {
            anyhow::bail!("LLM n√£o retornou resposta para interven√ß√£o");
        }

        let intervention = response.choices[0].text.trim().to_string();
        info!("METACOG: Interven√ß√£o gerada ({} caracteres)", intervention.len());

        Ok(intervention)
    }
}

impl Default for MetacognitiveReflector {
    fn default() -> Self {
        Self::new()
    }
}

